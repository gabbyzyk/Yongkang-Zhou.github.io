---
permalink: /
classes: about-page
title: "About Me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

Welcome! Iâ€™m **Yongkang Zhou**, a second-year M.S. student in Computer Technology at East China Normal University (ECNU), advised by Prof. Junjie Yao. 

My current research focuses on building reliable and efficient **Large Language Model** systems, with a particular emphasis on **Retrieval-Augmented Generation**
and **Information Retrieval**. I am also open to broader directions where LLMs can be applied responsibly and effectively for societal benefit


ğŸ“°News
------
- ğŸ“„ **Jun 2025** â€” *GEAR: Graph-Efficient Augmented Retrieval* submitted to **ICDE 2026**
- ğŸ¤ **May 2025** â€” Presented **ProRAG** at **DASFAA 2025 (Oral Presentation)** in Singapore
- ğŸ‰ **Jan 2025** â€” Paper **ProRAG: Towards Reliable and Proficient AIGC-based Digital Avatar** accepted at **DASFAA 2025**


Publicatin
------
<div style="display: flex; align-items: flex-start; gap: 10px; margin-bottom: 2em;">
  <div style="width: 310px; height: auto; border-radius: 1px; box-shadow: 0 4px 5px rgba(0,0,0,0.6); overflow: hidden;">
    <img src="../assets/dasfaa.png" alt="DASFAA" style="width: 100%; height: 100%; object-fit: contain;" />
  </div>
  <div style="font-size: 0.7rem; line-height: 1;">
    <p style="margin: 0.3em 0;"> International Conference on Database Systems for Advanced Applicatio(DASFAA 2025)</p>
    <p style="margin: 0.3em 0;"><strong>ProRAG: Towards Reliable and Proficient AIGC-based Digital Avatar</strong></p>
    <p style="margin: 0.3em 0;"><strong>Zhou, Y.</strong>, Yan, M., Xu, G., Yao, J.</p>
    <p style="margin: 0.3em 0;"> Proposed ProRAG, a RAG framework with hierarchical retrieval and multimodal grounding for reliable digital avatar</p>
    <p style="margin-top: 4em ;">
      ğŸ“‘ <a href="../assets/dasfaa25_pw.pdf">PDF</a> &nbsp;&nbsp;
      ğŸ› ï¸ <a href="https://github.com/gabbyzyk/GEAR" target="_blank">Code</a>
    </p>
  </div>
</div>

Under Review
------
<div style="display: flex; align-items: flex-start; gap: 10px; margin-bottom: 2em;">
  <div style="width: 421px; height: auto; border-radius: 1px; box-shadow: 0 4px 5px rgba(0,0,0,0.6); overflow: hidden;">
    <img src="../assets/icde.png" alt="ICDE" style="width: 100%; height: 100%; object-fit: contain;" />
  </div>
  <div style="font-size: 0.7rem; line-height: 1;">
    <p style="margin: 0.3em 0;">IEEE International Conference on Data Engineering (ICDE 2026) </p>
    <p style="margin: 0.3em 0;"><strong>GEAR: Graph-efficient Augmented Retrieval via Adaptive Knowledge-path Fusion</strong></p>
    <p style="margin: 0.3em 0;"><strong>Zhou, Y.</strong>, Quan, X., Hou, Y., Xu, G., Wang, J., Yao, J.</p>
    <p style="margin: 0.3em 0;">Developed GEAR, a multi-head graph retrieval framework that improves accuracy and efficiency by fusing diverse pattern
spaces and subgraph structures</p>
    <p style="margin-top: 4em 0;">
      ğŸ“‘ <a href="../assets/ICDE2026_pw.pdf">PDF</a> &nbsp;&nbsp;
    </p>
  </div>
</div>

<div style="display: flex; align-items: flex-start; gap: 10px; margin-bottom: 2em;">
  <div style="width: 463px; height: auto; border-radius: 1px; box-shadow: 0 4px 5px rgba(0,0,0,0.6); overflow: hidden;">
    <img src="../assets/cikm.png" alt="CIKM" style="width: 100%; height: 100%; object-fit: contain;" />
  </div>
  <div style="font-size: 0.7rem; line-height: 1;">
    <p style="margin: 0.3em 0;">ACM International Conference on Information and Knowledge Management (CIKM 2025)  </p>
    <p style="margin: 0.3em 0;"><strong>ThoughtForest-KGQA: A Multi-chain Tree Search for Knowledge Graph Reasoning</strong></p>
    <p style="margin: 0.3em 0;">Quan, X., <strong>Zhou, Y.</strong>, Yao, J.</p>
    <p style="margin: 0.3em 0;">Developed ThoughtForest-KGQA, a hierarchical reinforcement learning framework using multi-chain tree search for
multi-hop question answering over knowledge graphs</p>
    <p style="margin-top: 4em 0;">
      ğŸ“‘ <a href="../assets/CIKM2025_pw.pdf">PDF</a> &nbsp;&nbsp;
    </p>
  </div>
</div>



[Curriculum Vitae](../assets/Curriculum_Vitae.pdf).
