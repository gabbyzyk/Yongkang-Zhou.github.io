---
permalink: /
classes: about-page
title: "About Me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

Welcome! Iâ€™m **Yongkang Zhou**, a second-year M.S. student in Computer Technology at East China Normal University (ECNU), advised by Prof. Junjie Yao. 

My current research focuses on building reliable and efficient **Large Language Model** systems, with a particular emphasis on **Retrieval-Augmented Generation**
and **Information Retrieval**. I am also open to broader directions where LLMs can be applied responsibly and effectively for societal benefit


ðŸ“°News
------
- ðŸ“„ **Jun 2025** â€” *GEAR: Graph-Efficient Augmented Retrieval* submitted to **ICDE 2026**
- ðŸŽ¤ **May 2025** â€” Presented **ProRAG** at **DASFAA 2025 (Oral Presentation)** in Singapore
- ðŸŽ‰ **Jan 2025** â€” Paper **ProRAG: Towards Reliable and Proficient AIGC-based Digital Avatar** accepted at **DASFAA 2025**


Publicatin
------
<div style="display: flex; align-items: flex-start; gap: 10px; margin-bottom: 2em;">
  <div style="width: 390px; height: auto; border-radius: 1px; box-shadow: 0 4px 5px rgba(0,0,0,0.6); overflow: hidden;">
    <img src="../assets/dasfaa.png" alt="DASFAA" style="width: 100%; height: 100%; object-fit: contain;" />
  </div>
  <div style="font-size: 0.7rem; line-height: 0.7;">
    <p> International Conference on Database Systems for Advanced Applicatio(DASFAA 2025)</p>
    <p><strong>ProRAG: Towards Reliable and Proficient AIGC-based Digital Avatar</strong></p>
    <p><strong>Zhou, Y.</strong>, Yan, M., Xu, G., Yao, J.</p>
    <p> Proposed ProRAG, a RAG framework with hierarchical retrieval and multimodal grounding for reliable digital avatar</p>
  </div>
</div>

Under Review
------
<div style="display: flex; align-items: flex-start; gap: 10px; margin-bottom: 2em;">
  <div style="width: 390px; height: auto; border-radius: 1px; box-shadow: 0 4px 5px rgba(0,0,0,0.6); overflow: hidden;">
    <img src="../assets/icde.png" alt="ICDE" style="width: 100%; height: 100%; object-fit: contain;" />
  </div>
  <div style="font-size: 0.7rem; line-height: 0.7;">
    <p>IEEE International Conference on Data Engineering (ICDE 2026) â€” Submitted (Under Review)</p>
    <p><strong>GEAR: Graph-efficient Augmented Retrieval via Adaptive Knowledge-path Fusion</strong></p>
    <p><strong>Zhou, Y.</strong>, Quan, X., Hou, Y., Xu, G., Wang, J., Yao, J.</p>
    <p>Developed GEAR, a multi-head graph retrieval framework that improves accuracy and efficiency by fusing diverse pattern
spaces and subgraph structures</p>
  </div>
</div>

<div style="display: flex; align-items: flex-start; gap: 10px; margin-bottom: 2em;">
  <div style="width: 390px; height: auto; border-radius: 1px; box-shadow: 0 4px 5px rgba(0,0,0,0.6); overflow: hidden;">
    <img src="../assets/cikm.png" alt="CIKM" style="width: 100%; height: 100%; object-fit: contain;" />
  </div>
  <div style="font-size: 0.7rem; line-height: 0.7;">
    <p>ACM International Conference on Information and Knowledge Management (CIKM 2025) â€” Submitted (Under Review)</p>
    <p><strong>ThoughtForest-KGQA: A Multi-chain Tree Search for Knowledge Graph Reasoning</strong></p>
    <p>Quan, X., <strong>Zhou, Y.</strong>, Yao, J.</p>
    <p>Developed ThoughtForest-KGQA, a hierarchical reinforcement learning framework using multi-chain tree search for
multi-hop question answering over knowledge graphs</p>
  </div>
</div>



[Curriculum Vitae](../assets/Curriculum_Vitae.pdf).
